{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from collections import namedtuple\n",
    "plt.rcParams[\"font.sans-serif\"]=[\"SimHei\"] #设置字体\n",
    "plt.rcParams[\"axes.unicode_minus\"]=False #该语句解决图像中的“-”负号的乱码问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_nb(X, y):\n",
    "    '''\n",
    "    拉普拉斯修正的朴素贝叶斯分类训练\n",
    "    输入：\n",
    "        X:样本特征\n",
    "        y:样本标签\n",
    "    返回：\n",
    "        p1:好瓜概率\n",
    "        p1_list:正例中，各属性的条件概率，格式为色泽(is_continuous=False, conditional_pro=青绿  0.363636 乌黑  0.454545 浅白  0.181818)\n",
    "        p0_list:负例中，各属性的条件概率\n",
    "    '''\n",
    "    m, n = X.shape\n",
    "    p1 = (len(y[y == 1]) + 1) / (m + 2)  # 拉普拉斯平滑\n",
    "    print(p1)\n",
    "    p1_list = []  # 用于保存正例下各属性的条件概率\n",
    "    p0_list = []\n",
    "\n",
    "    X1 = X[y == 1]\n",
    "    X0 = X[y == 0]\n",
    "\n",
    "    m1, _ = X1.shape\n",
    "    m0, _ = X0.shape\n",
    "\n",
    "    for i in range(n): # 遍历数据集每个特征列\n",
    "        xi = X.iloc[:, i]\n",
    "        p_xi = namedtuple(X.columns[i], ['is_continuous', 'conditional_pro'])  # 用于储存每个变量的情况\n",
    "        is_continuous = type_of_target(xi) == 'continuous'\n",
    "        xi1 = X1.iloc[:, i]\n",
    "        xi0 = X0.iloc[:, i]\n",
    "        if is_continuous:  # 连续值时，conditional_pro 储存的就是 [mean, var] 即均值和方差\n",
    "            xi1_mean = np.mean(xi1)\n",
    "            xi1_var = np.var(xi1)\n",
    "            xi0_mean = np.mean(xi0)\n",
    "            xi0_var = np.var(xi0)\n",
    "\n",
    "            p1_list.append(p_xi(is_continuous, [xi1_mean, xi1_var]))\n",
    "            p0_list.append(p_xi(is_continuous, [xi0_mean, xi0_var]))\n",
    "        else:  # 离散值时直接计算各类别的条件概率\n",
    "            unique_value = xi.unique()  # 取值情况\n",
    "            nvalue = len(unique_value)  # 取值个数\n",
    "\n",
    "            xi1_value_count = pd.value_counts(xi1).reindex(unique_value).fillna(0) + 1  # 计算正样本中，该属性每个取值的数量，并且加1，即拉普拉斯平滑\n",
    "            xi0_value_count = pd.value_counts(xi0).reindex(unique_value).fillna(0) + 1\n",
    "\n",
    "            p1_list.append(p_xi(is_continuous, xi1_value_count / (m1 + nvalue)))\n",
    "            p0_list.append(p_xi(is_continuous, xi0_value_count / (m0 + nvalue)))\n",
    "    print(p1_list)\n",
    "    return p1, p1_list, p0_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_nb(x, p1, p1_list, p0_list):\n",
    "    '''\n",
    "    预测函数\n",
    "    输入：\n",
    "        x:一个样本\n",
    "    返回：\n",
    "        预测结果和概率\n",
    "    '''\n",
    "    n = len(x)\n",
    "\n",
    "    x_p1 = p1\n",
    "    x_p0 = 1 - p1\n",
    "    for i in range(n):\n",
    "        p1_xi = p1_list[i]\n",
    "        p0_xi = p0_list[i]\n",
    "\n",
    "        if p1_xi.is_continuous:\n",
    "            mean1, var1 = p1_xi.conditional_pro\n",
    "            mean0, var0 = p0_xi.conditional_pro\n",
    "            x_p1 += 1 / (np.sqrt(2 * np.pi) * var1) * np.exp(- (x[i] - mean1) ** 2 / (2 * var1 ** 2))\n",
    "            x_p0 += 1 / (np.sqrt(2 * np.pi) * var0) * np.exp(- (x[i] - mean0) ** 2 / (2 * var0 ** 2))\n",
    "        else:\n",
    "            x_p1 += p1_xi.conditional_pro[x[i]]\n",
    "            x_p0 += p0_xi.conditional_pro[x[i]]\n",
    "\n",
    "    if x_p1 > x_p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125748502994012\n",
      "[gender(is_continuous=False, conditional_pro=0    0.308333\n",
      "1    0.691667\n",
      "Name: gender, dtype: float64), ssc_p(is_continuous=True, conditional_pro=[70.94627118644065, 74.40820474001723]), hsc_p(is_continuous=True, conditional_pro=[69.23838983050848, 78.18790164464238]), degree_p(is_continuous=True, conditional_pro=[68.38669491525422, 42.32035094082161]), workex(is_continuous=False, conditional_pro=0    0.558333\n",
      "1    0.441667\n",
      "Name: workex, dtype: float64), etest_p(is_continuous=True, conditional_pro=[72.59788135593222, 181.80710144355078]), specialisation(is_continuous=False, conditional_pro=0    0.65\n",
      "1    0.35\n",
      "Name: specialisation, dtype: float64), mba_p(is_continuous=True, conditional_pro=[62.23203389830505, 33.56381959207125]), dummy_Arts(is_continuous=False, conditional_pro=1    0.05\n",
      "0    0.95\n",
      "Name: dummy_Arts, dtype: float64), dummy_Commerce(is_continuous=False, conditional_pro=0    0.475\n",
      "1    0.525\n",
      "Name: dummy_Commerce, dtype: float64), dummy_Science(is_continuous=False, conditional_pro=0    0.566667\n",
      "1    0.433333\n",
      "Name: dummy_Science, dtype: float64), dummy_Comm_Mgmt(is_continuous=False, conditional_pro=1    0.683333\n",
      "0    0.316667\n",
      "Name: dummy_Comm_Mgmt, dtype: float64), dummy_Others(is_continuous=False, conditional_pro=0    0.958333\n",
      "1    0.041667\n",
      "Name: dummy_Others, dtype: float64), dummy_Sci_Tech(is_continuous=False, conditional_pro=0    0.716667\n",
      "1    0.283333\n",
      "Name: dummy_Sci_Tech, dtype: float64)]\n",
      "Accurancy: 0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "X=pd.read_csv(\"X.csv\",index_col=0)\n",
    "y=pd.read_csv(\"y.csv\",index_col=0)\n",
    "y=y[\"status\"]\n",
    "m,n=X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,random_state=1)\n",
    "p1, p1_list, p0_list = train_nb(X_train, y_train)\n",
    "y_pred=[]\n",
    "for i in range(len(X_test)):\n",
    "    X_test_one = X_test.iloc[i, :]\n",
    "    y_pred.append(predict_nb(X_test_one, p1, p1_list, p0_list))\n",
    "print(\"Accurancy:\",np.mean(y_pred==y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
