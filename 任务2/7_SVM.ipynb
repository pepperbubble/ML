{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_support_(clf, X_, y_, kernel, c):\n",
    "    pos = y_ == 1\n",
    "    neg = y_ == -1\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    x_tmp = np.linspace(0, 1, 600)\n",
    "    y_tmp = np.linspace(0, 0.8, 600)\n",
    "\n",
    "    X_tmp, Y_tmp = np.meshgrid(x_tmp, y_tmp)\n",
    "\n",
    "    Z_rbf = clf.predict(np.c_[X_tmp.ravel(), Y_tmp.ravel()]).reshape(X_tmp.shape)\n",
    "\n",
    "    # ax.contourf(X_, Y_, Z_rbf, alpha=0.75)\n",
    "    cs = ax.contour(X_tmp, Y_tmp, Z_rbf, [0], colors='orange', linewidths=1)\n",
    "    ax.clabel(cs, fmt={cs.levels[0]: ''})\n",
    "\n",
    "\n",
    "    ax.scatter(X_[pos, 0], X_[pos, 1], label='1', color='r')\n",
    "    ax.scatter(X_[neg, 0], X_[neg, 1], label='0', color='y')\n",
    "\n",
    "\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title('{} kernel, C={}'.format(kernel, c))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class mySVM(object):\n",
    "\n",
    "    def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto', tol=1e-3, max_iter=-1, seed=16):\n",
    "        self.C = C\n",
    "        assert kernel in ('linear', 'rbf')\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.seed = seed\n",
    "        self._gamma = None\n",
    "\n",
    "        self.alphas = None\n",
    "        self._nonzero_alpha = None\n",
    "        self._e_cache = None\n",
    "        self._bound_alpha = None\n",
    "        self.b = None\n",
    "\n",
    "        self.support_ = None\n",
    "        self.support_vector_ = None\n",
    "        self.support_y_ = None\n",
    "        self.support_alpha_ = None\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        m = X.shape[0]\n",
    "        output = np.ones((m,))\n",
    "        for i in range(m):\n",
    "\n",
    "            kX_i = self._kX_i(self.support_vector_, X[i]) \n",
    "            gx = np.dot((self.support_alpha_.reshape(-1, 1) * self.support_y_).T, kX_i) + self.b  #g(x)=w*k(x)+b=αyk(x)+b 公式7.104\n",
    "\n",
    "            if gx < 0:\n",
    "                output[i] = 0\n",
    "            else:\n",
    "                output[i] = 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        if self.gamma == 'auto':\n",
    "            self._gamma = 1.0 / X.shape[1]\n",
    "        else:\n",
    "            self._gamma = self.gamma\n",
    "\n",
    "        self.alphas = np.zeros((X.shape[0],))\n",
    "        self.b = 0\n",
    "        self._nonzero_alpha = np.zeros((X.shape[0],), dtype=bool)  # 用于记录非零值的alphas的bool数组，\n",
    "        self._bound_alpha = np.zeros((X.shape[0],))  # 用于记录 (0, C)之间的alphas(即间隔边界点), 1表示当前位置的alphas为边界点\n",
    "        self._e_cache = np.zeros((X.shape[0],))\n",
    "\n",
    "        self._smo(X, y)\n",
    "\n",
    "        self.support_ = self._nonzero_alpha.nonzero()[0]\n",
    "        self.support_vector_ = X[self.support_]\n",
    "        self.support_y_ = y[self.support_]\n",
    "        self.support_alpha_ = self.alphas[self._nonzero_alpha]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _smo(self, X, y):\n",
    "        '''\n",
    "        第一层循环选择第一个变量，smo选择第一个变量的逻辑是：\n",
    "        1：首先遍历所有 0 < ai < C 的样本点，若不满足KKT条件则选择第二变量，进行着两个变量的调优。\n",
    "        2：直到所有 0 < ai < C 的样本点都满足KKT条件，那么而后遍历所有样本点，对不满足KKT条件的ai进行调优。\n",
    "        3：若2步骤有对找到可以进行调优的ai，那么回到1。否则返回所有ai。\n",
    "        '''\n",
    "        iter = 0  # 记录迭代次数\n",
    "        entire_flag = True  # 表示是否需要遍历全部样本的flag。因将所有ai初始化为0，没有0 < ai < C的样本，所以第一次必定遍历全部样本。\n",
    "        m = X.shape[0]\n",
    "        while (self.max_iter == -1) or (iter < self.max_iter):  # 若参max_iter == -1, 则直到所有样本都符合kkt条件才停止。\n",
    "            # out loop 寻找第一个alpha\n",
    "            alpha_pairs_changed = 0\n",
    "\n",
    "            if entire_flag:\n",
    "                for i in range(m):\n",
    "                    alpha_pairs_changed += self._inner_loop(X, y, i)\n",
    "\n",
    "            else:\n",
    "                bound_index = self._bound_alpha.nonzero()[0]\n",
    "                for i in bound_index:\n",
    "                    alpha_pairs_changed += self._inner_loop(X, y, i)\n",
    "            iter += 1\n",
    "\n",
    "            if entire_flag:  # 若这次遍历所有样本，则下一次将遍历 0 < ai < C 的样本点\n",
    "                if alpha_pairs_changed == 0:  # 若遍历所有样本都没有更新ai(等价于所有样本都满足KKT条件)，则直接停止更新。\n",
    "                    return self\n",
    "                entire_flag = False\n",
    "\n",
    "            elif alpha_pairs_changed == 0:  # 若遍历 0 < ai < C的所有样本，都没有更新ai，则下一次遍历所有样本\n",
    "                entire_flag = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _inner_loop(self, X, y, i):\n",
    "        '''\n",
    "        inner loop 寻找第二个alpha\n",
    "        若更新成功返回1，没有更新返回0\n",
    "        '''\n",
    "        if self._bound_alpha[i]:\n",
    "            Ei = self._e_cache[i]\n",
    "        else:\n",
    "            Ei = self._clac_Ei(X, y, i)\n",
    "        m = X.shape[0]\n",
    "        yi = y[i, :]\n",
    "        ai = self.alphas[i]\n",
    "\n",
    "        if ((yi * Ei < -self.tol) and (ai < self.C)) or ((yi * Ei > self.tol) and (ai > 0)):  # 该alpha 违背kkt条件\n",
    "            best_j = None\n",
    "            if np.sum(self._bound_alpha) > 0:  # 存在bound的alpha 则从中选择一个是的|Ei - Ej|最大的一个j\n",
    "                j, Ej = self._select_second_alpha(Ei)\n",
    "                if self._update_alpha(X, y, i, j, Ei, Ej):  # 若成功更新了alpha 则直接返回1\n",
    "                    return 1\n",
    "                best_j = j\n",
    "\n",
    "\n",
    "            # 如果还找不到合适的aj就遍历所有alpha\n",
    "            for j in np.random.permutation(m): \n",
    "                Ej = self._clac_Ei(X, y, j)\n",
    "                if self._update_alpha(X, y, i, j, Ei, Ej):\n",
    "                    return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def _update_alpha(self, X, y, i, j, Ei, Ej=None):\n",
    "        if i == j:\n",
    "            return 0\n",
    "        alpha_i_old = self.alphas[i].copy()\n",
    "        alpha_j_old = self.alphas[j].copy()\n",
    "\n",
    "        yi = y[i, 0]\n",
    "        yj = y[j, 0]\n",
    "\n",
    "        if yi != yj:\n",
    "            L = max(0, alpha_j_old - alpha_i_old)\n",
    "            H = min(self.C, self.C + alpha_j_old - alpha_i_old)\n",
    "        else:\n",
    "            L = max(0, alpha_j_old + alpha_i_old - self.C)\n",
    "            H = min(self.C, alpha_j_old + alpha_i_old)\n",
    "        if L == H:\n",
    "            return 0\n",
    "        kii = self._kij(X, i, i)\n",
    "        kjj = self._kij(X, j, j)\n",
    "        kij = self._kij(X, i, j)\n",
    "\n",
    "        eta = kii + kjj - 2 * kij  #《统计学习方法》p127 式7.107\n",
    "\n",
    "        if eta == 0:\n",
    "            return 0\n",
    "\n",
    "        alpha_j_new = alpha_j_old + yj * (Ei - Ej) / eta   #α2=α2+y2(E1-E2)/η\n",
    "        alpha_j_new = self._clip_alpha(alpha_j_new, H, L)\n",
    "\n",
    "        if abs(alpha_j_new - alpha_j_old) < 0.00001:  # 没有足够的更新，就直接更新失败。\n",
    "            return 0\n",
    "\n",
    "        alpha_i_new = alpha_i_old + yi * yj * (alpha_j_old - alpha_j_new)\n",
    "\n",
    "        bj = self.b - Ej - yj * kjj * (alpha_j_new - alpha_j_old) - yi * kij * (alpha_i_new - alpha_i_old) #b1=-E1-y1K11(a1new-a1old)-y2K21(a2new-a2old)+b1\n",
    "        bi = self.b - Ei - yi * kij * (alpha_j_new - alpha_j_old) - yi * kii * (alpha_i_new - alpha_i_old)\n",
    "\n",
    "        # 更新alpha\n",
    "        if 0 < alpha_j_new < self.C:\n",
    "            self.b = bj\n",
    "        elif 0 < alpha_i_new < self.C:\n",
    "            self.b = bi\n",
    "        else:\n",
    "            self.b = (bi + bj) / 2\n",
    "\n",
    "        self.alphas[i] = alpha_i_new\n",
    "        self.alphas[j] = alpha_j_new\n",
    "\n",
    "        self._update_alpha_adjoint_arr(alpha_i_new, i)\n",
    "        self._update_alpha_adjoint_arr(alpha_j_new, j)\n",
    "\n",
    "        self._update_e_cache(X, y)\n",
    "        return 1\n",
    "\n",
    "    def _update_alpha_adjoint_arr(self, alpha_new, i):\n",
    "        '''\n",
    "        更新 self._bound_alpha 和 self._nonzero_alpha\n",
    "        '''\n",
    "        self._nonzero_alpha[i] = (alpha_new > 0)\n",
    "        self._bound_alpha[i] = int(0 < alpha_new < self.C)\n",
    "\n",
    "    def _update_e_cache(self, X, y):\n",
    "        '''更新bound对应的误差缓存'''\n",
    "\n",
    "        for i in self._bound_alpha.nonzero()[0]:\n",
    "            self._e_cache[i] = self._clac_Ei(X, y, i)\n",
    "\n",
    "    def _select_second_alpha(self, Ei):\n",
    "        '''\n",
    "        计算最大的|Ei - Ej|\n",
    "        '''\n",
    "        bound_index = self._bound_alpha.nonzero()[0]\n",
    "        delta_E = np.abs(Ei - self._e_cache[bound_index])\n",
    "        j = bound_index[np.argmax(delta_E)]\n",
    "        Ej = self._e_cache[j]\n",
    "\n",
    "        return j, Ej\n",
    "\n",
    "    def _clac_Ei(self, X, y, i):\n",
    "        '''\n",
    "        Ei为函数g(x)对输入xi的预测值与真实输出yi之差\n",
    "        参考《统计学习方法中》p127, 式7.104 - 7.105\n",
    "        '''\n",
    "\n",
    "        xi = X[[i], :]\n",
    "        yi = y[i, 0]\n",
    "        if self._nonzero_alpha.any():\n",
    "            valid_X = X[self._nonzero_alpha]  # 这里仅使用非零值的\n",
    "            valid_y = y[self._nonzero_alpha]\n",
    "            valid_alphas = self.alphas[self._nonzero_alpha]\n",
    "            kX_i = self._kX_i(valid_X, xi)\n",
    "            gx = np.dot((valid_alphas.reshape(-1, 1) * valid_y).T, kX_i) + self.b\n",
    "\n",
    "        else:  # 当所有alpha\n",
    "            gx = self.b\n",
    "\n",
    "        Ei = gx - yi\n",
    "        return np.squeeze(Ei)\n",
    "\n",
    "    def _kX_i(self, X, xi):\n",
    "        '''\n",
    "\n",
    "        :param X:  (n_bound, m)\n",
    "        :param xi: (1, m)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        if self.kernel == 'linear':\n",
    "            kX_i = np.dot(X, xi.T)\n",
    "        else:\n",
    "            kX_i = np.exp(-self._gamma * np.sum(np.power(X - xi, 2), axis=1))\n",
    "\n",
    "        return kX_i\n",
    "\n",
    "    def _kij(self, X, i, j):\n",
    "        '''\n",
    "        核函数\n",
    "        :param X:\n",
    "        :param i:\n",
    "        :param j:\n",
    "        :return:    K(i, j)\n",
    "        '''\n",
    "        xi = X[[i], :]\n",
    "        xj = X[[j], :]\n",
    "\n",
    "        if self.kernel == 'linear':\n",
    "            kX_i = np.dot(xj, xi.T)\n",
    "        else:\n",
    "            kX_i = np.exp(-self._gamma * np.sum(np.power(xj - xi, 2), axis=1))\n",
    "\n",
    "        return np.squeeze(kX_i)\n",
    "\n",
    "    def _clip_alpha(self, aj, H, L):\n",
    "        if aj > H:\n",
    "            aj = H\n",
    "        if aj < L:\n",
    "            aj = L\n",
    "        return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv(\"X.csv\",index_col=0)\n",
    "y=pd.read_csv(\"y.csv\",index_col=0)\n",
    "y=y[\"status\"]\n",
    "y[y == 0] = -1\n",
    "m,n=X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "y_train=y_train.values\n",
    "X_test=X_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "clf = mySVM(C=100,kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accurancy:\",np.mean(y_test==y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
