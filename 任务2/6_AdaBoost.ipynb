{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import type_of_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.split_point = None\n",
    "        self.deep = None\n",
    "        self.left_tree = None\n",
    "        self.right_tree = None\n",
    "        self.leaf_class = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gini(y, D):\n",
    "    '''\n",
    "    计算样本集y下的加权基尼指数\n",
    "    :param y: 数据样本标签\n",
    "    :param D: 样本权重\n",
    "    :return:  加权后的基尼指数\n",
    "    '''\n",
    "    unique_class = np.unique(y)\n",
    "    total_weight = np.sum(D)\n",
    "\n",
    "    gini = 1\n",
    "    for c in unique_class:\n",
    "        gini -= (np.sum(D[y == c]) / total_weight) ** 2\n",
    "\n",
    "    return gini\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcMinGiniIndex(a, y, D):\n",
    "    '''\n",
    "    计算特征a下样本集y的的基尼指数\n",
    "    :param a: 单一特征值\n",
    "    :param y: 数据样本标签\n",
    "    :param D: 样本权重\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    feature = np.sort(a)\n",
    "    total_weight = np.sum(D)\n",
    "\n",
    "    split_points = [(feature[i] + feature[i + 1]) / 2 for i in range(feature.shape[0] - 1)]\n",
    "\n",
    "    min_gini = float('inf')\n",
    "    min_gini_point = None\n",
    "\n",
    "    for i in split_points:\n",
    "        yv1 = y[a <= i]\n",
    "        yv2 = y[a > i]\n",
    "\n",
    "        Dv1 = D[a <= i]\n",
    "        Dv2 = D[a > i]\n",
    "        gini_tmp = (np.sum(Dv1) * gini(yv1, Dv1) + np.sum(Dv2) * gini(yv2, Dv2)) / total_weight\n",
    "\n",
    "        if gini_tmp < min_gini:\n",
    "            min_gini = gini_tmp\n",
    "            min_gini_point = i\n",
    "\n",
    "    return min_gini, min_gini_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chooseFeatureToSplit(X, y, D):\n",
    "    '''\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param D:\n",
    "    :return: 特征索引, 分割点\n",
    "    '''\n",
    "    gini0, split_point0 = calcMinGiniIndex(X[:, 0], y, D)\n",
    "    gini1, split_point1 = calcMinGiniIndex(X[:, 1], y, D)\n",
    "\n",
    "    if gini0 > gini1:\n",
    "        return 1, split_point1\n",
    "    else:\n",
    "        return 0, split_point0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createSingleTree(X, y, D, deep=0):\n",
    "    '''\n",
    "    这里以gini指数决策树作为基学习器，限定深度为2\n",
    "    :param X: 训练集特征\n",
    "    :param y: 训练集标签\n",
    "    :param D: 训练样本权重\n",
    "    :param deep: 树的深度\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    node = Node()\n",
    "    node.deep = deep\n",
    "\n",
    "    if (deep == 2) | (X.shape[0] <= 2):  # 当前分支下，样本数量小于等于2 或者 深度达到2时，直接设置为叶节点\n",
    "        pos_weight = np.sum(D[y == 1])\n",
    "        neg_weight = np.sum(D[y == -1])\n",
    "        if pos_weight > neg_weight:\n",
    "            node.leaf_class = 1\n",
    "        else:\n",
    "            node.leaf_class = -1\n",
    "\n",
    "        return node\n",
    "\n",
    "    feature_index, split_point = chooseFeatureToSplit(X, y, D)\n",
    "\n",
    "    node.feature_index = feature_index\n",
    "    node.split_point = split_point\n",
    "\n",
    "    left = X[:, feature_index] <= split_point\n",
    "    right = X[:, feature_index] > split_point\n",
    "\n",
    "    node.left_tree = createSingleTree(X[left, :], y[left], D[left], deep + 1)\n",
    "    node.right_tree = createSingleTree(X[right, :], y[right], D[right], deep + 1)\n",
    "\n",
    "    return node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictSingle(tree, x):\n",
    "    '''\n",
    "    基于基学习器，预测单个样本\n",
    "    :param tree:\n",
    "    :param x:\n",
    "    :return:\n",
    "    '''\n",
    "    if tree.leaf_class is not None:\n",
    "        return tree.leaf_class\n",
    "\n",
    "    if x[tree.feature_index] > tree.split_point:\n",
    "        return predictSingle(tree.right_tree, x)\n",
    "    else:\n",
    "        return predictSingle(tree.left_tree, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictBase(tree, X):\n",
    "    '''\n",
    "    基于基学习器预测所有样本\n",
    "    :param tree:\n",
    "    :param X:\n",
    "    :return:\n",
    "    '''\n",
    "    result = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        result.append(predictSingle(tree, X[i, :]))\n",
    "\n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adaBoostTrain(X, y, tree_num=5):\n",
    "    '''\n",
    "    以深度为2的决策树作为基学习器，训练adaBoost\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param tree_num:\n",
    "    :return:\n",
    "    '''\n",
    "    D = np.ones(y.shape) / y.shape  # 初始化权重\n",
    "\n",
    "    trees = []  # 所有基学习器\n",
    "    a = []  # 基学习器对应权重\n",
    "\n",
    "\n",
    "    for _ in range(tree_num):\n",
    "        tree = createSingleTree(X, y, D)\n",
    "\n",
    "        hx = predictBase(tree, X)\n",
    "        err_rate = np.sum(D[hx != y])\n",
    "\n",
    "        at = np.log((1 - err_rate) / max(err_rate, 1e-16)) / 2\n",
    "\n",
    "        trees.append(tree)\n",
    "        a.append(at)\n",
    "\n",
    "        if (err_rate > 0.5) | (err_rate == 0):  # 错误率大于0.5 或者 错误率为0时，则直接停止\n",
    "            break\n",
    "\n",
    "        # 更新每个样本权重\n",
    "\n",
    "        D = D * np.exp(-y*hx*at)\n",
    "        D = D / np.sum(D)\n",
    "\n",
    "    return trees, a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adaBoostPredict(X, trees, a):\n",
    "    agg_est = np.zeros((X.shape[0],))\n",
    "\n",
    "    for tree, am in zip(trees, a):\n",
    "        agg_est += am * predictBase(tree, X)\n",
    "\n",
    "    result = np.ones((X.shape[0],))\n",
    "\n",
    "    result[agg_est < 0] = 0\n",
    "\n",
    "    return result.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv(\"X.csv\",index_col=0)\n",
    "y=pd.read_csv(\"y.csv\",index_col=0)\n",
    "y=y[\"status\"]\n",
    "y[y == 0] = -1\n",
    "m,n=X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "y_train=y_train.values\n",
    "X_test=X_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy: 0.5952380952380952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trees, a= adaBoostTrain(X_train, y_train,tree_num=10)\n",
    "y_pred=adaBoostPredict(X_test,trees,a)\n",
    "print(\"Accurancy:\",np.mean(y_pred==y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
